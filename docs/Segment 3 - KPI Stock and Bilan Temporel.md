# Segment 3 ‚Äî KPI Stock + Bilan temporel : calculs et agr√©gation

**Guide technique complet pour le moteur d'indicateurs du GLPI Dashboard**

---

Le module KPI constitue le c≈ìur analytique de l'application. Il transforme les donn√©es brutes pars√©es (Segment 1) et stock√©es en SQLite (Segment 2) en indicateurs actionnables pour le pilotage du stock de tickets. Ce guide couvre l'int√©gralit√© de la logique de calcul : classification vivant/termin√©, statistiques d'√¢ge, distribution par tranches, analyse de charge technicien, flux temporels entr√©e/sortie, et ventilation multi-dimensionnelle. L'architecture retenue est un **mod√®le hybride SQL + Rust** : les comptages, sommes et agr√©gations group√©es s'ex√©cutent en SQLite (scan unique, pas de transfert de donn√©es), tandis que les m√©dianes, percentiles et scores composites se calculent en m√©moire sur des `Vec<f64>` Rust. Pour ‚â§ 50 000 tickets, l'ensemble des KPI du tableau de bord se calcule en **moins de 5 ms**.

---

## 1. R√©f√©rence des statuts GLPI 9.5 et classification vivant/termin√©

### 1.1 Les six statuts standard

GLPI 9.5 d√©finit exactement **six statuts de ticket** sous forme de constantes PHP dans `CommonITILObject`. Ces statuts sont cod√©s en dur (non configurables en base) et apparaissent dans les exports CSV sous forme de libell√©s fran√ßais, pas de codes num√©riques.

|Code|Constante PHP|Libell√© CSV fran√ßais|Classification|
|:-:|---|---|:-:|
|**1**|`INCOMING`|`Nouveau`|**Vivant**|
|**2**|`ASSIGNED`|`En cours (Attribu√©)`|**Vivant**|
|**3**|`PLANNED`|`En cours (Planifi√©)`|**Vivant**|
|**4**|`WAITING`|`En attente`|**Vivant**|
|**5**|`SOLVED`|`R√©solu`|**Termin√©**|
|**6**|`CLOSED`|`Clos`|**Termin√©**|

Le champ `est_vivant` dans la table `tickets` correspond directement √† la m√©thode interne GLPI `getNotSolvedStatusArray()`, qui retourne les statuts 1 √† 4. **Les statuts 5 (R√©solu) et 6 (Clos) sont tous deux "termin√©"**, bien qu'ITIL distingue la r√©solution (le technicien d√©clare le correctif) de la cl√¥ture (le demandeur confirme ou la cl√¥ture automatique se d√©clenche apr√®s un d√©lai configurable).

### 1.2 Donn√©es r√©elles de l'export CPAM 92

L'analyse du fichier `tickets.csv` (9 616 tickets) r√©v√®le la distribution suivante :

|Statut|Nombre|%|Classification|
|---|--:|--:|:-:|
|Clos|9 070|94,3%|Termin√©|
|En cours (Attribu√©)|330|3,4%|Vivant|
|En attente|187|1,9%|Vivant|
|En cours (Planifi√©)|23|0,24%|Vivant|
|R√©solu|3|0,03%|Termin√©|
|Nouveau|3|0,03%|Vivant|
|**Total vivants**|**543**|**5,6%**||
|**Total termin√©s**|**9 073**|**94,4%**||

**Observations cl√©s :**

- La quasi-totalit√© des termin√©s sont `Clos` (99,97%), ce qui indique que la cl√¥ture automatique GLPI fonctionne correctement apr√®s r√©solution
- Seulement 3 tickets `R√©solu` non encore clos ‚Äî la fen√™tre de transition R√©solu ‚Üí Clos est tr√®s courte
- Le ratio vivants/termin√©s (~5,6%) est sain pour un export combinant stock et historique

### 1.3 Priorit√©s r√©elles

L'export contient **sept valeurs de priorit√©**, dont une non standard :

|Priorit√©|Total|Dont vivants|Poids recommand√©|
|---|--:|:-:|:-:|
|Moyenne|5 163|268|3|
|Haute|3 802|223|5|
|Basse|590|47|2|
|Tr√®s basse|37|5|1|
|Tr√®s haute|17|0|8|
|Majeure|7|0|10|

**`Majeure` est une priorit√© non standard** ‚Äî elle n'existe pas dans le GLPI vanilla 9.5 (qui s'arr√™te √† Tr√®s haute). Elle a probablement √©t√© ajout√©e via personnalisation GLPI locale ou plugin. Les 7 tickets concern√©s sont tous `Clos`, tous de type `Demande`, avec urgence `Tr√®s haute`. Le parser doit accepter cette valeur sans erreur et lui attribuer le poids le plus √©lev√©.

### 1.4 Groupes de techniciens ‚Äî structure hi√©rarchique r√©elle

Les groupes suivent une hi√©rarchie √† 2-3 niveaux s√©par√©s par `>` :

|Groupe complet|Niveau 1|Niveau 2|Niveau 3|Tickets|
|---|---|---|---|--:|
|`_DSI > _SUPPORT UTILISATEURS ET POSTES DE TRAVAIL`|_DSI|_SUPPORT UTILISATEURS ET POSTES DE TRAVAIL|‚Äî|6 562|
|`_DSI > _PRODUCTION-INFRASTRUCTURES`|_DSI|_PRODUCTION-INFRASTRUCTURES|‚Äî|1 474|
|`_DSI > _SERVICE DES CORRESPONDANTS INFORMATIQUE`|_DSI|_SERVICE DES CORRESPONDANTS INFORMATIQUE|‚Äî|1 178|
|`_DSI > _HABILITATIONS_PRODUCTION`|_DSI|_HABILITATIONS_PRODUCTION|‚Äî|302|
|`_DSI > _SUPPORT ... > _SUPPORT - PARC`|_DSI|_SUPPORT UTIL...|_SUPPORT - PARC|165|
|`_DSI > _DIADEME`|_DSI|_DIADEME|‚Äî|31|
|`_DSI > _DEVELOPPEMENT & INDUSTRIALISATION`|_DSI|_DEVELOPPEMENT & INDUSTRIALISATION|‚Äî|24|
|`GC_SD`|GC_SD|‚Äî|‚Äî|1|

**Attention** : le champ `Attribu√© √† - Groupe de techniciens` peut √™tre multilignes (plusieurs groupes assign√©s s√©par√©s par `\n`). Le parsing split sur `\n` puis chaque ligne est d√©coup√©e sur `>` pour extraire les niveaux hi√©rarchiques. Le caract√®re `&amp;` dans `_DEVELOPPEMENT & INDUSTRIALISATION` est une entit√© HTML ‚Äî le crate csv le d√©s√©rialise tel quel en `&amp;`, il faut le d√©coder en `&` lors de la normalisation.

### 1.5 Code Rust de classification

```rust
/// Classifie un statut GLPI comme vivant (true) ou termin√© (false).
/// G√®re les 6 statuts standard GLPI 9.5.
/// Les statuts inconnus sont class√©s comme vivants par s√©curit√©
/// (mieux vaut suivre un ticket de trop que d'en oublier un).
pub fn est_vivant(statut: &str) -> bool {
    !matches!(statut.trim(), "Clos" | "R√©solu")
}

/// Retourne le poids de pond√©ration pour une priorit√© GLPI.
/// Inclut "Majeure" (non standard, pr√©sent dans l'export CPAM 92).
/// Pond√©ration exponentielle : un P1 consomme plus de ressources que cinq P4.
pub fn poids_priorite(priorite: &str) -> f64 {
    match priorite.trim() {
        "Majeure"    => 10.0,
        "Tr√®s haute" => 8.0,
        "Haute"      => 5.0,
        "Moyenne"    => 3.0,
        "Basse"      => 2.0,
        "Tr√®s basse" => 1.0,
        _            => 1.0,  // Valeur inconnue ‚Üí poids minimal
    }
}

/// Parse la hi√©rarchie de groupe : "_DSI > _SUPPORT > _PARC" ‚Üí ["_DSI", "_SUPPORT", "_PARC"]
pub fn parse_groupe_hierarchy(groupe_complet: &str) -> Vec<String> {
    groupe_complet
        .split(" > ")
        .map(|s| {
            s.trim()
                .replace("&amp;", "&")  // D√©coder les entit√©s HTML
                .to_string()
        })
        .filter(|s| !s.is_empty())
        .collect()
}

/// Cycle de vie d'un ticket GLPI :
/// Nouveau ‚Üí En cours (Attribu√©) ‚Üí En cours (Planifi√©) ‚Üí En attente ‚Üí R√©solu ‚Üí Clos
///                                                    ‚Üñ reboucle possible ‚Üó
pub fn lifecycle_order(statut: &str) -> u8 {
    match statut {
        "Nouveau"              => 1,
        "En cours (Attribu√©)"  => 2,
        "En cours (Planifi√©)"  => 3,
        "En attente"           => 4,
        "R√©solu"               => 5,
        "Clos"                 => 6,
        _                      => 0,
    }
}
```

---

## 2. Calculs KPI du stock : √¢ge, distribution et charge

Le module KPI stock analyse l'**inventaire courant des tickets ouverts** (vivants d'un import donn√©). Ces m√©triques r√©pondent √† la question : ¬´ Quel est l'√©tat de sant√© de notre stock en ce moment ? ¬ª

### 2.1 Statistiques d'√¢ge des tickets ouverts

Pour chaque ticket vivant, `anciennete_jours` (pr√©-calcul√© lors du parsing CSV, en jours depuis `date_ouverture`) constitue le vecteur d'entr√©e pour l'analyse statistique. Les quatre m√©triques fondamentales sont :

- **Moyenne** : tendance g√©n√©rale, sensible aux valeurs extr√™mes
- **M√©diane** : centre robuste insensible aux outliers (un ticket de 5 ans ne la fausse pas)
- **√âcart-type** : dispersion ‚Äî un √©cart-type √©lev√© signifie un stock h√©t√©rog√®ne (tickets r√©cents + fossiles)
- **P90** : s√©v√©rit√© de la queue ‚Äî ¬´ 90% des tickets sont plus jeunes que X jours ¬ª

Les benchmarks MetricNet/HDI pour le support de proximit√© placent le temps moyen de r√©solution autour de **8,85 heures ouvr√©es** pour les incidents. Pour une CPAM avec une charge mixte incidents/demandes, un √¢ge moyen du stock ouvert inf√©rieur √† **10 jours ouvr√©s** est un objectif raisonnable.

#### Fonctions statistiques en Rust pur

Aucun crate externe n'est n√©cessaire pour ~10K valeurs. Le tri d'un `Vec<f64>` de 10 000 √©l√©ments prend ~50¬µs.

```rust
// src-tauri/src/stats.rs

/// Moyenne arithm√©tique.
pub fn moyenne(data: &[f64]) -> Option<f64> {
    if data.is_empty() { return None; }
    Some(data.iter().sum::<f64>() / data.len() as f64)
}

/// M√©diane (valeur centrale apr√®s tri).
pub fn mediane(data: &[f64]) -> Option<f64> {
    if data.is_empty() { return None; }
    let mut sorted = data.to_vec();
    sorted.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
    let n = sorted.len();
    if n % 2 == 1 {
        Some(sorted[n / 2])
    } else {
        Some((sorted[n / 2 - 1] + sorted[n / 2]) / 2.0)
    }
}

/// √âcart-type population (œÉ, pas l'estimateur œÉÃÇ avec n-1).
/// On utilise la population car on a l'int√©gralit√© des tickets, pas un √©chantillon.
pub fn ecart_type(data: &[f64]) -> Option<f64> {
    let m = moyenne(data)?;
    let variance = data.iter()
        .map(|x| (x - m).powi(2))
        .sum::<f64>() / data.len() as f64;
    Some(variance.sqrt())
}

/// Percentile par interpolation lin√©aire (identique au d√©faut NumPy).
/// `p` dans [0.0, 100.0]. Utiliser 90.0 pour P90, 95.0 pour P95.
pub fn percentile(data: &[f64], p: f64) -> Option<f64> {
    if data.is_empty() || !(0.0..=100.0).contains(&p) { return None; }
    let mut sorted = data.to_vec();
    sorted.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
    let n = sorted.len();
    if n == 1 { return Some(sorted[0]); }
    let rank = (p / 100.0) * (n - 1) as f64;
    let lower = rank.floor() as usize;
    let upper = rank.ceil() as usize;
    let frac = rank - lower as f64;
    Some(sorted[lower] * (1.0 - frac) + sorted[upper] * frac)
}

/// Coefficient de variation (CV = œÉ/Œº). Mesure l'homog√©n√©it√©.
/// CV < 0.2 = tr√®s homog√®ne, CV > 0.5 = forte dispersion.
pub fn coefficient_variation(data: &[f64]) -> Option<f64> {
    let m = moyenne(data)?;
    if m == 0.0 { return None; }
    let s = ecart_type(data)?;
    Some(s / m)
}
```

### 2.2 Distribution par tranches d'√¢ge

Les seuils **>30j, >60j, >90j, >180j, >365j** sont align√©s avec les pratiques industrielles. BMC Helix ITSM, InvGate et Supportbench utilisent tous les paliers 30/60/90 jours pour les tableaux de bord op√©rationnels. Les extensions 180 et 365 jours sont des ajouts pragmatiques pour les organisations ayant un historique de backlog ‚Äî courant dans le secteur public comme la CPAM.

#### Requ√™te SQL en un seul scan

```sql
SELECT
    CASE
        WHEN anciennete_jours < 8    THEN '< 1 sem'
        WHEN anciennete_jours < 30   THEN '1-4 sem'
        WHEN anciennete_jours < 60   THEN '30-60j'
        WHEN anciennete_jours < 90   THEN '60-90j'
        WHEN anciennete_jours < 180  THEN '90-180j'
        WHEN anciennete_jours < 365  THEN '180-365j'
        ELSE '> 1 an'
    END AS tranche_age,
    COUNT(*) AS nb_tickets,
    ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER (), 1) AS pourcentage
FROM tickets
WHERE import_id = ?1 AND est_vivant = 1
GROUP BY tranche_age
ORDER BY
    CASE tranche_age
        WHEN '< 1 sem'  THEN 1  WHEN '1-4 sem'  THEN 2
        WHEN '30-60j'   THEN 3  WHEN '60-90j'    THEN 4
        WHEN '90-180j'  THEN 5  WHEN '180-365j'  THEN 6
        WHEN '> 1 an'   THEN 7
    END;
```

La tranche `< 1 sem` (moins de 8 jours) a √©t√© ajout√©e car elle capture les tickets frais susceptibles d'√™tre r√©solus rapidement ‚Äî une information utile pour le pilotage quotidien.

### 2.3 Tickets sans suivi et inactivit√©

Les tickets avec `nombre_suivis = 0` sont des ¬´ tickets zombies ¬ª ‚Äî cr√©√©s mais jamais travaill√©s. C'est un indicateur de qualit√© critique. Combin√© avec `inactivite_jours` (jours depuis `derniere_modification`), il r√©v√®le les tickets n√©glig√©s.

**Donn√©es r√©elles CPAM 92** : sur 543 vivants, **263 n'ont aucun suivi** (48,4%). C'est un signal d'alerte majeur ‚Äî presque la moiti√© du stock ouvert n'a jamais √©t√© touch√©.

La bonne pratique est de signaler les tickets avec **z√©ro suivi ET √¢g√©s de plus de 7 jours** comme n√©cessitant une action imm√©diate.

```sql
-- Tickets zombies : vivants, sans suivi, √¢g√©s de plus de 7 jours
SELECT COUNT(*) AS nb_zombies
FROM tickets
WHERE import_id = ?1
  AND est_vivant = 1
  AND (nombre_suivis IS NULL OR nombre_suivis = 0)
  AND anciennete_jours > 7;
```

### 2.4 Score de charge pond√©r√© par la priorit√©

Une pond√©ration lin√©aire simple (Tr√®s haute=5, Haute=4, Moyenne=3, Basse=2, Tr√®s basse=1) fonctionne mais sous-pond√®re les tickets critiques. Une **pond√©ration exponentielle** refl√®te mieux la r√©alit√© o√π un seul P1 peut consommer plus de ressources que cinq P4 :

Le **score de backlog pond√©r√©** est `Œ£(tickets_√†_priorit√©_i √ó poids_i)`. Ce nombre unique permet de suivre si la composition du backlog se d√©grade m√™me quand le total reste stable.

```rust
/// Score de charge pond√©r√© d'un ensemble de tickets.
/// Prend en compte la priorit√© et l'anciennet√© pour une mesure composite.
pub fn score_charge_pondere(
    tickets: &[(i64, &str)],  // (anciennete_jours, priorite)
) -> f64 {
    tickets.iter().map(|(age, prio)| {
        let poids = poids_priorite(prio);
        // Facteur d'√¢ge : un ticket vieux p√®se plus lourd
        let facteur_age = if *age > 90 { 2.0 }
            else if *age > 30 { 1.5 }
            else { 1.0 };
        poids * facteur_age
    }).sum()
}
```

### 2.5 Analyse de charge par technicien

Les benchmarks HDI sur 1 000 entreprises situent la charge moyenne √† **491 tickets r√©solus par technicien par mois** pour le support de premier niveau. La notion de seuil de stock (nombre maximum de tickets ouverts simultan√©ment) est plus pertinente pour le pilotage quotidien ‚Äî le CDC d√©finit un seuil par d√©faut de **20 tickets** par technicien, param√©trable.

L'√©quilibre de charge au sein de l'√©quipe se mesure par le **coefficient de variation** (CV = œÉ/Œº des tickets par technicien) : CV < 0,2 indique un bon √©quilibre, CV > 0,5 r√©v√®le un d√©s√©quilibre significatif.

```rust
use std::collections::HashMap;

/// R√©sultat d'analyse de charge pour un technicien.
#[derive(Debug, Clone, serde::Serialize)]
#[serde(rename_all = "camelCase")]
pub struct ChargeParTechnicien {
    pub nom: String,
    pub nb_vivants: i64,
    pub par_statut: VentilationStatut,
    pub incidents: i64,
    pub demandes: i64,
    pub moyenne_anciennete: f64,
    pub mediane_anciennete: f64,
    pub nb_haute_priorite: i64,      // Haute + Tr√®s haute + Majeure
    pub nb_plus_90j: i64,
    pub nb_sans_suivi: i64,
    pub nb_inactifs_14j: i64,
    pub score_charge: f64,
    pub ecart_seuil: i64,            // nb_vivants - seuil (n√©gatif = sous le seuil)
    pub couleur: String,             // "vert", "jaune", "orange", "rouge"
}

/// Ventilation par statut pour un sous-ensemble de tickets.
#[derive(Debug, Clone, Default, serde::Serialize)]
#[serde(rename_all = "camelCase")]
pub struct VentilationStatut {
    pub nouveau: i64,
    pub en_cours_attribue: i64,
    pub en_cours_planifie: i64,
    pub en_attente: i64,
    pub resolu: i64,
    pub clos: i64,
}

impl VentilationStatut {
    pub fn incrementer(&mut self, statut: &str) {
        match statut {
            "Nouveau"              => self.nouveau += 1,
            "En cours (Attribu√©)"  => self.en_cours_attribue += 1,
            "En cours (Planifi√©)"  => self.en_cours_planifie += 1,
            "En attente"           => self.en_attente += 1,
            "R√©solu"               => self.resolu += 1,
            "Clos"                 => self.clos += 1,
            _                      => {} // Statut inconnu
        }
    }
}

/// Construit l'analyse de charge par technicien en un seul scan SQL + agr√©gation Rust.
pub fn build_charge_par_technicien(
    conn: &rusqlite::Connection,
    import_id: i64,
    seuil_tickets: i64,
) -> Result<Vec<ChargeParTechnicien>, crate::error::AppError> {
    let mut stmt = conn.prepare_cached(
        "SELECT technicien_principal, statut, type_ticket, priorite,
                anciennete_jours, inactivite_jours, nombre_suivis
         FROM tickets
         WHERE import_id = ?1 AND est_vivant = 1
           AND technicien_principal IS NOT NULL
           AND technicien_principal != ''"
    )?;

    // Accumulateur par technicien
    struct Accum {
        ages: Vec<f64>,
        ventilation: VentilationStatut,
        incidents: i64,
        demandes: i64,
        haute_prio: i64,
        plus_90j: i64,
        sans_suivi: i64,
        inactifs_14j: i64,
        score: f64,
    }

    let mut groups: HashMap<String, Accum> = HashMap::new();
    let mut rows = stmt.query(rusqlite::params![import_id])?;

    while let Some(row) = rows.next()? {
        let tech: String = row.get(0)?;
        let statut: String = row.get(1)?;
        let type_t: String = row.get(2)?;
        let prio: String = row.get(3)?;
        let age: f64 = row.get::<_, Option<i64>>(4)?.unwrap_or(0) as f64;
        let inact: Option<i64> = row.get(5)?;
        let suivis: i64 = row.get::<_, Option<i64>>(6)?.unwrap_or(0);

        let acc = groups.entry(tech).or_insert_with(|| Accum {
            ages: Vec::new(),
            ventilation: VentilationStatut::default(),
            incidents: 0, demandes: 0,
            haute_prio: 0, plus_90j: 0, sans_suivi: 0, inactifs_14j: 0,
            score: 0.0,
        });

        acc.ages.push(age);
        acc.ventilation.incrementer(&statut);
        match type_t.as_str() {
            "Incident" => acc.incidents += 1,
            "Demande"  => acc.demandes += 1,
            _ => {}
        }
        if matches!(prio.as_str(), "Haute" | "Tr√®s haute" | "Majeure") {
            acc.haute_prio += 1;
        }
        if age > 90.0 { acc.plus_90j += 1; }
        if suivis == 0 { acc.sans_suivi += 1; }
        if inact.unwrap_or(0) > 14 { acc.inactifs_14j += 1; }

        // Score composite : priorit√© √ó facteur d'√¢ge
        let facteur_age = if age > 90.0 { 2.0 } else if age > 30.0 { 1.5 } else { 1.0 };
        acc.score += poids_priorite(&prio) * facteur_age;
    }

    let mut result: Vec<ChargeParTechnicien> = groups.into_iter()
        .map(|(nom, acc)| {
            let nb = acc.ages.len() as i64;
            let moy = crate::stats::moyenne(&acc.ages).unwrap_or(0.0);
            let med = crate::stats::mediane(&acc.ages).unwrap_or(0.0);
            let couleur = couleur_charge(nb, seuil_tickets);

            ChargeParTechnicien {
                nom,
                nb_vivants: nb,
                par_statut: acc.ventilation,
                incidents: acc.incidents,
                demandes: acc.demandes,
                moyenne_anciennete: (moy * 10.0).round() / 10.0,
                mediane_anciennete: med,
                nb_haute_priorite: acc.haute_prio,
                nb_plus_90j: acc.plus_90j,
                nb_sans_suivi: acc.sans_suivi,
                nb_inactifs_14j: acc.inactifs_14j,
                score_charge: (acc.score * 10.0).round() / 10.0,
                ecart_seuil: nb - seuil_tickets,
                couleur,
            }
        })
        .collect();

    // Tri par score de charge d√©croissant (les plus surcharg√©s en premier)
    result.sort_by(|a, b| b.score_charge.partial_cmp(&a.score_charge)
        .unwrap_or(std::cmp::Ordering::Equal));

    Ok(result)
}
```

---

## 3. Codes couleur et seuils RAG

Le syst√®me **RAG (Red/Amber/Green)** est le standard universel ITSM. Pour un public fran√ßais, le sch√©ma √† quatre couleurs vert/jaune/orange/rouge offre une granularit√© plus fine tout en restant intuitif.

### 3.1 Seuils de charge technicien

Avec un seuil par d√©faut de **20 tickets** par technicien (param√©trable via la table `config`) :

|Couleur|Condition|Interpr√©tation|
|---|:-:|---|
|**Vert** üü¢|‚â§ 50% du seuil (‚â§ 10)|Charge confortable|
|**Jaune** üü°|51‚Äì100% du seuil (11‚Äì20)|Charge nominale, √† surveiller|
|**Orange** üü†|101‚Äì200% du seuil (21‚Äì40)|Surcharge, action n√©cessaire|
|**Rouge** üî¥|> 200% du seuil (> 40)|Surcharge critique, intervention urgente|

```rust
/// D√©termine le code couleur en fonction de la charge et du seuil.
pub fn couleur_charge(nb_vivants: i64, seuil: i64) -> String {
    if seuil == 0 { return "rouge".to_string(); }
    let ratio = nb_vivants as f64 / seuil as f64;
    match ratio {
        r if r <= 0.5 => "vert".to_string(),
        r if r <= 1.0 => "jaune".to_string(),
        r if r <= 2.0 => "orange".to_string(),
        _             => "rouge".to_string(),
    }
}
```

### 3.2 Seuils d'anciennet√© des tickets

|Couleur|Anciennet√©|Signification|
|---|:-:|---|
|**Vert** üü¢|< 30 jours|Normal, dans la fen√™tre de r√©solution attendue|
|**Jaune** üü°|30‚Äì60 jours|Vieillissant, n√©cessite un suivi|
|**Orange** üü†|60‚Äì90 jours|Zone de risque, escalade recommand√©e|
|**Rouge** üî¥|> 90 jours|Backlog critique, action imm√©diate|

```rust
pub fn couleur_anciennete(jours: i64) -> &'static str {
    match jours {
        0..=29    => "vert",
        30..=59   => "jaune",
        60..=89   => "orange",
        _         => "rouge",
    }
}
```

### 3.3 Indicateur de sant√© du delta stock

Le **ratio sortie/entr√©e** est le signal cl√© : l'objectif est ‚â• 1,0, c'est-√†-dire que l'√©quipe r√©sout au moins autant de tickets qu'il en arrive. Un ratio durablement inf√©rieur √† 1,0 signifie que le backlog cro√Æt ind√©finiment.

|Couleur|Delta stock|Interpr√©tation|
|---|:-:|---|
|**Vert** üü¢|‚â§ 0 (stock en baisse)|Backlog ma√Ætris√©|
|**Jaune** üü°|+1 √† +10%|Croissance mod√©r√©e, surveiller|
|**Orange** üü†|+10 √† +25%|Croissance significative|
|**Rouge** üî¥|> +25%|Critique : stock en spirale|

---

## 4. Analyse temporelle : le moteur de bilan

Le bilan temporel reconstruit la dynamique des flux de tickets √† partir d'un export CSV ponctuel. Puisque l'application ne dispose que d'**une seule photographie** (pas de donn√©es time-series continues), le taux de cr√©ation est d√©riv√© de `date_ouverture` et le taux de cl√¥ture est approxim√© via `date_cloture_approx` (lui-m√™me d√©riv√© de `derniere_modification` pour les tickets termin√©s).

### 4.1 Approximation de la date de cl√¥ture via `derniere_modification`

Le champ `date_cloture_approx` stocke la date de cl√¥ture estim√©e. Le champ `date_mod` interne de GLPI se met √† jour √† **chaque modification** : changement de statut, ajout de suivi, ajout de t√¢che, modification de champ, et m√™me les actions automatiques du cron (comme `closeticket` qui fait passer R√©solu ‚Üí Clos apr√®s un d√©lai configurable).

**Pour la majorit√© des tickets termin√©s, `derniere_modification` est une bonne approximation de la date de cl√¥ture**, car la derni√®re action sur un ticket typique est le changement de statut vers R√©solu ou Clos. Toutefois, trois cas d√©gradent cette approximation :

1. **Modifications post-cl√¥ture** : quand un administrateur reclassifie des cat√©gories, lance des mises √† jour en masse, ou ajoute des notes administratives aux tickets clos. Chaque action pousse `date_mod` au-del√† de la cl√¥ture r√©elle.
    
2. **D√©lai de cl√¥ture automatique** : la `closedate` est fix√©e quand le cron GLPI s'ex√©cute, pas quand le ticket a √©t√© r√©solu. Si la cl√¥ture automatique est configur√©e √† 7 jours apr√®s r√©solution, `date_mod` refl√®te le moment d'ex√©cution du cron.
    
3. **Cycles de r√©ouverture** (R√©solu ‚Üí En cours ‚Üí R√©solu √† nouveau) : chaque cycle met √† jour `date_mod`. Le `date_mod` final refl√®te la derni√®re r√©solution, pas la premi√®re.
    

**Recommandation** : utiliser `derniere_modification` comme proxy acceptable pour l'analyse de tendance, mais le documenter comme une approximation. Si une pr√©cision sup√©rieure est n√©cessaire, conseiller √† l'utilisateur d'ajouter les colonnes `Date de cl√¥ture` et `Date de r√©solution` √† sa vue de recherche GLPI avant l'export CSV.

```rust
/// Lors de la normalisation du ticket : attribuer date_cloture_approx
fn date_cloture_approx(statut: &str, derniere_modification: &Option<String>) -> Option<String> {
    if !est_vivant(statut) {
        derniere_modification.clone()
    } else {
        None
    }
}
```

### 4.2 Calcul des flux entr√©e/sortie par p√©riode

**Entr√©es** (cr√©√©s) par p√©riode : exact pour tous les tickets pr√©sents dans l'export ‚Äî chaque `date_ouverture` est le timestamp de cr√©ation. **Sorties** (r√©solus/clos) par p√©riode : approxim√© via `date_cloture_approx` pour les tickets termin√©s.

**Caveat critique** : les tickets qui ont √©t√© cr√©√©s ET clos avant l'export mais ne figurent pas dans l'extraction sont invisibles. Les taux historiques sous-estiment donc √† la fois la cr√©ation et la cl√¥ture. L'approximation s'am√©liore pour les p√©riodes r√©centes et se d√©grade pour les plus anciennes.

#### Requ√™te SQL ‚Äî agr√©gation mensuelle avec delta

```sql
WITH periodes AS (
    -- Union de tous les mois ayant vu une cr√©ation ou une cl√¥ture
    SELECT DISTINCT strftime('%Y-%m', date_ouverture) AS mois
    FROM tickets WHERE import_id = ?1
    UNION
    SELECT DISTINCT strftime('%Y-%m', date_cloture_approx)
    FROM tickets WHERE import_id = ?1 AND date_cloture_approx IS NOT NULL
),
crees AS (
    SELECT strftime('%Y-%m', date_ouverture) AS mois, COUNT(*) AS n
    FROM tickets WHERE import_id = ?1
    GROUP BY mois
),
resolus AS (
    SELECT strftime('%Y-%m', date_cloture_approx) AS mois, COUNT(*) AS n
    FROM tickets WHERE import_id = ?1 AND date_cloture_approx IS NOT NULL
    GROUP BY mois
)
SELECT p.mois,
       COALESCE(c.n, 0) AS nb_crees,
       COALESCE(r.n, 0) AS nb_resolus,
       COALESCE(c.n, 0) - COALESCE(r.n, 0) AS delta
FROM periodes p
LEFT JOIN crees c ON p.mois = c.mois
LEFT JOIN resolus r ON p.mois = r.mois
ORDER BY p.mois;
```

#### Agr√©gation hebdomadaire (semaines ISO)

SQLite 3.46.0+ supporte `%G` (ann√©e ISO semaine) et `%V` (num√©ro de semaine ISO). **Toujours coupler `%G` avec `%V`** ‚Äî ne jamais utiliser `%Y` avec `%V`, car aux fronti√®res d'ann√©e l'ann√©e ISO peut diff√©rer de l'ann√©e calendaire (ex : le 31 d√©cembre 2024 peut appartenir √† 2025-W01).

```sql
-- CORRECT : groupement par semaine ISO
SELECT strftime('%G-S%V', date_ouverture) AS semaine_iso,
       COUNT(*) AS nb_crees
FROM tickets WHERE import_id = ?1
GROUP BY semaine_iso ORDER BY semaine_iso;

-- INCORRECT (erreur fr√©quente) : m√©lange ann√©e calendaire et semaine ISO
-- strftime('%Y-S%V', date_ouverture)  -- FAUX aux fronti√®res d'ann√©e !
```

Pour les versions SQLite ant√©rieures √† 3.46.0, le fallback en Rust via chrono est recommand√© :

```rust
use chrono::{Datelike, NaiveDateTime};

/// "2026-01-05T16:24:00" ‚Üí "2026-S02"
pub fn semaine_iso_label(dt: &NaiveDateTime) -> String {
    let iw = dt.date().iso_week();
    format!("{:04}-S{:02}", iw.year(), iw.week())
}

/// "2026-01-05T16:24:00" ‚Üí "2026-01"
pub fn mois_label(dt: &NaiveDateTime) -> String {
    format!("{:04}-{:02}", dt.year(), dt.month())
}

/// "2026-01-05T16:24:00" ‚Üí "2026-01-05"
pub fn jour_label(dt: &NaiveDateTime) -> String {
    format!("{}", dt.date())
}
```

**L'agr√©gation hebdomadaire est la granularit√© la plus utile** pour le pilotage op√©rationnel ITSM : elle lisse le bruit quotidien tout en √©tant assez fine pour d√©tecter les tendances. La granularit√© mensuelle convient au reporting strat√©gique/manag√©rial.

### 4.3 Estimation du stock cumul√©

La courbe de stock cumul√© √† la p√©riode `t` est `Stock(t) = Stock(t-1) + delta(t)`. Puisque le stock initial est inconnu √† partir d'un seul export, on le calcule **√† rebours** depuis le stock courant connu : `Stock_actuel = COUNT(est_vivant = 1)`. En remontant les deltas mensuels, on reconstruit la courbe historique.

```rust
/// Calcule le stock cumul√© √† rebours √† partir du stock actuel connu.
/// `rows` doit √™tre tri√© par p√©riode croissante.
/// `stock_actuel` = nombre de tickets vivants dans l'import courant.
pub fn calculer_stock_cumule(
    rows: &mut [BilanTemporelRow],
    stock_actuel: i64,
) {
    let n = rows.len();
    if n == 0 { return; }

    // La derni√®re p√©riode se termine au stock actuel
    rows[n - 1].stock_cumule = Some(stock_actuel);

    // Remonter dans le temps : stock(i) = stock(i+1) - delta(i+1)
    for i in (0..n - 1).rev() {
        let stock_suivant = rows[i + 1].stock_cumule.unwrap_or(0);
        let delta_suivant = rows[i + 1].delta;
        rows[i].stock_cumule = Some(stock_suivant - delta_suivant);
    }
}
```

**Pourquoi √† rebours plut√¥t qu'en avant ?** Le calcul en avant (`Stock(t) = Œ£(cr√©√©s jusqu'√† t) - Œ£(r√©solus jusqu'√† t)`) ne compte que les tickets visibles dans le snapshot. Les tickets cr√©√©s et clos avant l'export mais absents de l'extraction sont invisibles ‚Üí le stock initial serait artificiellement bas. Le calcul √† rebours ancre la courbe sur le **stock actuel connu** (fiable car c'est un comptage direct), ce qui produit des estimations historiques plus r√©alistes.

---

## 5. Structures de donn√©es IPC

Tous les types utilisent `#[serde(rename_all = "camelCase")]` pour que le frontend React re√ßoive des cl√©s JSON en camelCase.

### 5.1 R√©sultat KPI Stock global

```rust
use serde::Serialize;

/// Vue d'ensemble du stock pour les KPI cards du tableau de bord.
#[derive(Debug, Clone, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct StockKpiResult {
    // Comptages globaux
    pub total_vivants: i64,
    pub total_termines: i64,

    // Ventilation par statut
    pub par_statut: Vec<StatutCount>,

    // Statistiques d'√¢ge des vivants
    pub age_moyen_jours: f64,
    pub age_median_jours: f64,
    pub age_ecart_type: f64,
    pub age_p90_jours: f64,
    pub age_p95_jours: f64,

    // Ventilation type
    pub incidents_vivants: i64,
    pub demandes_vivants: i64,

    // Distribution par tranches d'anciennet√©
    pub distribution_age: Vec<DistributionAgeBucket>,

    // Indicateurs de qualit√©
    pub nb_sans_suivi: i64,
    pub pct_sans_suivi: f64,
    pub nb_inactifs_14j: i64,
    pub nb_inactifs_30j: i64,
    pub nb_inactifs_60j: i64,

    // Score de charge global pond√©r√©
    pub score_backlog_pondere: f64,

    // Sant√© de l'√©quipe
    pub nb_techniciens_actifs: i64,
    pub charge_moyenne_par_technicien: f64,
    pub cv_charge_techniciens: f64,          // Coefficient de variation
}

#[derive(Debug, Clone, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct StatutCount {
    pub statut: String,
    pub count: i64,
    pub est_vivant: bool,
    pub pourcentage: f64,
}

#[derive(Debug, Clone, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct DistributionAgeBucket {
    pub label: String,             // "< 1 sem", "1-4 sem", "30-60j", etc.
    pub seuil_min_jours: i64,
    pub seuil_max_jours: Option<i64>,   // None pour la derni√®re tranche
    pub count: i64,
    pub pourcentage: f64,
    pub couleur: String,           // Code couleur de la tranche
}
```

### 5.2 R√©sultat Bilan Temporel

```rust
/// R√©sultat complet du bilan temporel sur une p√©riode.
#[derive(Debug, Clone, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct BilanTemporelResult {
    pub granularite: String,        // "jour", "semaine", "mois"
    pub periodes: Vec<BilanTemporelRow>,
    pub totaux: BilanTotaux,
    pub ventilation: Option<Vec<BilanVentilation>>,
}

#[derive(Debug, Clone, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct BilanTemporelRow {
    pub periode: String,            // "2026-01", "2026-S05", "2026-01-15"
    pub label: String,              // "Janvier 2026", "Sem. 5", "15/01/2026"
    pub nb_crees: i64,
    pub nb_resolus: i64,
    pub delta: i64,                 // nb_crees - nb_resolus
    pub stock_cumule: Option<i64>,  // Estim√© par calcul √† rebours
    pub ratio_sortie_entree: Option<f64>,  // nb_resolus / nb_crees
}

#[derive(Debug, Clone, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct BilanTotaux {
    pub total_crees: i64,
    pub total_resolus: i64,
    pub delta_global: i64,
    pub moyenne_crees_par_periode: f64,
    pub moyenne_resolus_par_periode: f64,
    pub ratio_global_sortie_entree: f64,
}

#[derive(Debug, Clone, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct BilanVentilation {
    pub label: String,              // Nom du technicien/groupe/type
    pub nb_crees: i64,
    pub nb_resolus: i64,
    pub delta: i64,
    pub couleur_delta: String,
}
```

### 5.3 Requ√™te de bilan (entr√©e frontend ‚Üí backend)

```rust
use serde::Deserialize;

#[derive(Debug, Clone, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct BilanRequest {
    pub granularite: String,         // "jour", "semaine", "mois"
    pub date_debut: Option<String>,  // ISO 8601, None = depuis le d√©but
    pub date_fin: Option<String>,    // ISO 8601, None = jusqu'√† maintenant
    pub ventilation_par: Option<String>,  // "technicien", "groupe", "type"
}
```

### 5.4 Types miroir TypeScript

```typescript
// src/types/kpi.ts

export interface StockKpiResult {
  totalVivants: number;
  totalTermines: number;
  parStatut: StatutCount[];
  ageMoyenJours: number;
  ageMedianJours: number;
  ageEcartType: number;
  ageP90Jours: number;
  ageP95Jours: number;
  incidentsVivants: number;
  demandesVivants: number;
  distributionAge: DistributionAgeBucket[];
  nbSansSuivi: number;
  pctSansSuivi: number;
  nbInactifs14j: number;
  nbInactifs30j: number;
  nbInactifs60j: number;
  scoreBacklogPondere: number;
  nbTechniciensActifs: number;
  chargeMoyenneParTechnicien: number;
  cvChargeTechniciens: number;
}

export interface StatutCount {
  statut: string;
  count: number;
  estVivant: boolean;
  pourcentage: number;
}

export interface DistributionAgeBucket {
  label: string;
  seuilMinJours: number;
  seuilMaxJours: number | null;
  count: number;
  pourcentage: number;
  couleur: string;
}

export interface ChargeParTechnicien {
  nom: string;
  nbVivants: number;
  parStatut: VentilationStatut;
  incidents: number;
  demandes: number;
  moyenneAnciennete: number;
  medianeAnciennete: number;
  nbHautePriorite: number;
  nbPlus90j: number;
  nbSansSuivi: number;
  nbInactifs14j: number;
  scoreCharge: number;
  ecartSeuil: number;
  couleur: 'vert' | 'jaune' | 'orange' | 'rouge';
}

export interface VentilationStatut {
  nouveau: number;
  enCoursAttribue: number;
  enCoursPlanifie: number;
  enAttente: number;
  resolu: number;
  clos: number;
}

export interface BilanTemporelResult {
  granularite: 'jour' | 'semaine' | 'mois';
  periodes: BilanTemporelRow[];
  totaux: BilanTotaux;
  ventilation: BilanVentilation[] | null;
}

export interface BilanTemporelRow {
  periode: string;
  label: string;
  nbCrees: number;
  nbResolus: number;
  delta: number;
  stockCumule: number | null;
  ratioSortieEntree: number | null;
}

export interface BilanTotaux {
  totalCrees: number;
  totalResolus: number;
  deltaGlobal: number;
  moyenneCreesParPeriode: number;
  moyenneResolusParPeriode: number;
  ratioGlobalSortieEntree: number;
}

export interface BilanVentilation {
  label: string;
  nbCrees: number;
  nbResolus: number;
  delta: number;
  couleurDelta: string;
}

export interface BilanRequest {
  granularite: 'jour' | 'semaine' | 'mois';
  dateDebut?: string;
  dateFin?: string;
  ventilationPar?: 'technicien' | 'groupe' | 'type';
}
```

---

## 6. Ventilation multi-dimensionnelle : requ√™tes SQL

### 6.1 Tableau crois√© technicien √ó statut

SQLite n'a pas d'op√©rateur `PIVOT` natif. On utilise le pattern `SUM(CASE WHEN ... THEN 1 ELSE 0 END)` avec une expression CASE par statut connu :

```sql
SELECT
    technicien_principal,
    SUM(CASE WHEN statut = 'Nouveau' THEN 1 ELSE 0 END) AS nouveau,
    SUM(CASE WHEN statut = 'En cours (Attribu√©)' THEN 1 ELSE 0 END) AS attribue,
    SUM(CASE WHEN statut = 'En cours (Planifi√©)' THEN 1 ELSE 0 END) AS planifie,
    SUM(CASE WHEN statut = 'En attente' THEN 1 ELSE 0 END) AS en_attente,
    COUNT(*) AS total,
    ROUND(AVG(anciennete_jours), 1) AS age_moyen,
    SUM(CASE WHEN nombre_suivis = 0 THEN 1 ELSE 0 END) AS sans_suivi,
    SUM(CASE WHEN anciennete_jours > 90 THEN 1 ELSE 0 END) AS plus_90j,
    SUM(CASE WHEN inactivite_jours > 14 THEN 1 ELSE 0 END) AS inactif_14j
FROM tickets
WHERE import_id = ?1 AND est_vivant = 1
GROUP BY technicien_principal
ORDER BY total DESC;
```

### 6.2 Ventilation par groupe hi√©rarchique

Pour le comptage par groupe le plus sp√©cifique (sans double comptage) :

```sql
SELECT
    COALESCE(groupe_niveau3, groupe_niveau2, groupe_niveau1) AS groupe_effectif,
    groupe_niveau1,
    groupe_niveau2,
    COUNT(*) AS nb_tickets,
    SUM(CASE WHEN type_ticket = 'Incident' THEN 1 ELSE 0 END) AS incidents,
    SUM(CASE WHEN type_ticket = 'Demande' THEN 1 ELSE 0 END) AS demandes,
    COUNT(DISTINCT technicien_principal) AS nb_techniciens,
    ROUND(AVG(anciennete_jours), 1) AS age_moyen
FROM tickets
WHERE import_id = ?1 AND est_vivant = 1
GROUP BY groupe_effectif
ORDER BY nb_tickets DESC;
```

Pour la vue drill-down hi√©rarchique (avec comptages √† chaque niveau) :

```sql
-- Niveau 1 : agr√©gation la plus large
SELECT
    groupe_niveau1 AS groupe,
    1 AS niveau,
    COUNT(*) AS nb_tickets
FROM tickets
WHERE import_id = ?1 AND est_vivant = 1 AND groupe_niveau1 IS NOT NULL
GROUP BY groupe_niveau1

UNION ALL

-- Niveau 2 : sous-groupes
SELECT
    groupe_niveau1 || ' > ' || groupe_niveau2 AS groupe,
    2 AS niveau,
    COUNT(*) AS nb_tickets
FROM tickets
WHERE import_id = ?1 AND est_vivant = 1 AND groupe_niveau2 IS NOT NULL
GROUP BY groupe_niveau1, groupe_niveau2

ORDER BY niveau, nb_tickets DESC;
```

### 6.3 Gestion des tickets multi-assign√©s

Un ticket peut √™tre assign√© √† plusieurs techniciens et/ou plusieurs groupes (champs multilignes s√©par√©s par `\n`). La strat√©gie de comptage d√©pend du contexte :

|Contexte|Strat√©gie|Justification|
|---|---|---|
|Stock global|Compter **une fois** via `technicien_principal`|√âviter la surestimation du stock total|
|Vue par technicien|Compter une fois via `technicien_principal`|Le premier technicien est le responsable|
|Vue par groupe|Compter une fois via `groupe_principal`|Idem|
|Analyse de collaboration|Compter **par apparition**|Pour identifier les tickets partag√©s|
|Export plan d'action|Compter une fois par technicien principal|Un seul responsable par ticket|

Le champ `technicien_principal` (premier de la liste) est le bon axe de ventilation pour le pilotage quotidien. Les techniciens secondaires sont consult√©s, pas responsables.

### 6.4 Quand agr√©ger en SQL vs en Rust

|Op√©ration|Meilleur dans|Raison|
|---|:-:|---|
|COUNT/SUM/AVG + GROUP BY|**SQL**|Scan unique, pas de transfert|
|Tableaux crois√©s (CASE WHEN)|**SQL**|Scan unique efficace|
|Groupement temporel (strftime)|**SQL**|Fonctions de date natives|
|M√©diane, percentiles|**Rust**|SQLite n'a pas de percentile natif ; trier 10K f64 = ~50¬µs|
|Scores composites pond√©r√©s|**Rust**|Logique multi-champs plus lisible en code|
|Pivots dynamiques (colonnes inconnues)|**Rust construit le SQL**|Requ√™ter d'abord les valeurs DISTINCT, puis construire les colonnes CASE|
|Distribution par tranches d'√¢ge|**Les deux**|CASE SQL ou match Rust ‚Äî aussi rapides l'un que l'autre|

**R√®gle de coh√©rence** : encapsuler toutes les requ√™tes du tableau de bord dans une seule transaction en lecture pour garantir la coh√©rence des donn√©es :

```rust
pub fn charger_tableau_de_bord(
    conn: &rusqlite::Connection,
    import_id: i64,
) -> Result<TableauDeBord, crate::error::AppError> {
    // Transaction en lecture seule ‚Äî assure la coh√©rence entre toutes les requ√™tes
    let tx = conn.transaction_with_behavior(
        rusqlite::TransactionBehavior::Deferred
    )?;

    let stock_kpi = build_stock_kpi(&tx, import_id)?;
    let charge_techniciens = build_charge_par_technicien(&tx, import_id, 20)?;
    let ventilation_groupes = build_ventilation_groupes(&tx, import_id)?;

    // tx drop sans commit ‚Äî lecture seule, pas d'effet de bord
    Ok(TableauDeBord { stock_kpi, charge_techniciens, ventilation_groupes })
}
```

Toujours utiliser `prepare_cached()` pour les requ√™tes du tableau de bord ‚Äî √ßa r√©utilise les statements compil√©s et √©limine le surco√ªt de pr√©paration lors des rafra√Æchissements successifs.

---

## 7. Commandes Tauri et int√©gration IPC

### 7.1 Commande KPI Stock

```rust
// src-tauri/src/commands/stock.rs
use tauri::State;
use crate::state::{AppState, DbAccess};

#[tauri::command]
pub async fn get_stock_kpi(
    state: State<'_, AppState>,
) -> Result<StockKpiResult, String> {
    state.db(|conn| {
        let import_id = get_active_import_id(conn)?;
        build_stock_kpi(conn, import_id)
    })
}

#[tauri::command]
pub async fn get_charge_techniciens(
    state: State<'_, AppState>,
) -> Result<Vec<ChargeParTechnicien>, String> {
    state.db(|conn| {
        let import_id = get_active_import_id(conn)?;
        let seuil = get_config_value(conn, "seuil_tickets_technicien")?
            .parse::<i64>()
            .unwrap_or(20);
        build_charge_par_technicien(conn, import_id, seuil)
    })
}

/// R√©cup√®re l'ID de l'import actif.
fn get_active_import_id(conn: &rusqlite::Connection) -> Result<i64, rusqlite::Error> {
    conn.query_row(
        "SELECT id FROM imports WHERE is_active = 1 ORDER BY id DESC LIMIT 1",
        [],
        |row| row.get(0),
    )
}

/// R√©cup√®re une valeur de configuration.
fn get_config_value(conn: &rusqlite::Connection, key: &str) -> Result<String, rusqlite::Error> {
    conn.query_row(
        "SELECT value FROM config WHERE key = ?1",
        rusqlite::params![key],
        |row| row.get(0),
    )
}
```

### 7.2 Commande Bilan Temporel

```rust
// src-tauri/src/commands/bilan.rs

#[tauri::command]
pub async fn get_bilan_temporel(
    state: State<'_, AppState>,
    request: BilanRequest,
) -> Result<BilanTemporelResult, String> {
    state.db(|conn| {
        let import_id = get_active_import_id(conn)?;
        build_bilan_temporel(conn, import_id, &request)
    })
}
```

### 7.3 Appel depuis le frontend

```typescript
// src/hooks/useStockKpi.ts
import { useState, useEffect } from 'react';
import { invoke } from '@tauri-apps/api/core';
import type { StockKpiResult } from '../types/kpi';
import { useAppStore } from '../stores/appStore';

export function useStockKpi() {
  const [data, setData] = useState<StockKpiResult | null>(null);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const activeImportId = useAppStore((s) => s.activeImportId);

  useEffect(() => {
    if (!activeImportId) return;

    setLoading(true);
    invoke<StockKpiResult>('get_stock_kpi')
      .then(setData)
      .catch((err) => setError(typeof err === 'string' ? err : String(err)))
      .finally(() => setLoading(false));
  }, [activeImportId]);

  return { data, loading, error };
}

// src/hooks/useBilanTemporel.ts
import { invoke } from '@tauri-apps/api/core';
import type { BilanTemporelResult, BilanRequest } from '../types/kpi';

export async function fetchBilanTemporel(
  request: BilanRequest
): Promise<BilanTemporelResult> {
  return invoke<BilanTemporelResult>('get_bilan_temporel', { request });
}
```

---

## 8. Indicateurs ITIL compl√©mentaires

Au-del√† du stock et des flux, plusieurs m√©triques ITIL peuvent √™tre calcul√©es √† partir du m√™me jeu de donn√©es :

### 8.1 D√©lai moyen de r√©solution (MTTR)

Le **Mean Time To Resolve** se calcule comme la moyenne de `date_cloture_approx - date_ouverture` pour les tickets r√©solus.

```sql
SELECT
    ROUND(AVG(
        julianday(date_cloture_approx) - julianday(date_ouverture)
    ), 1) AS mttr_jours,
    -- Par type
    ROUND(AVG(CASE WHEN type_ticket = 'Incident'
        THEN julianday(date_cloture_approx) - julianday(date_ouverture)
    END), 1) AS mttr_incidents,
    ROUND(AVG(CASE WHEN type_ticket = 'Demande'
        THEN julianday(date_cloture_approx) - julianday(date_ouverture)
    END), 1) AS mttr_demandes
FROM tickets
WHERE import_id = ?1
  AND est_vivant = 0
  AND date_cloture_approx IS NOT NULL;
```

### 8.2 Taux de r√©solution au premier contact

Approxim√© par les tickets r√©solus avec `nombre_suivis ‚â§ 1`. L'objectif ITIL typique est **70‚Äì75%**.

```sql
SELECT
    COUNT(*) AS total_resolus,
    SUM(CASE WHEN nombre_suivis <= 1 THEN 1 ELSE 0 END) AS premier_contact,
    ROUND(100.0 * SUM(CASE WHEN nombre_suivis <= 1 THEN 1 ELSE 0 END)
        / NULLIF(COUNT(*), 0), 1) AS taux_premier_contact
FROM tickets
WHERE import_id = ?1 AND est_vivant = 0;
```

### 8.3 Distribution des d√©lais de r√©solution

Par tranches temporelles pour √©valuer la performance SLA :

```sql
SELECT
    CASE
        WHEN julianday(date_cloture_approx) - julianday(date_ouverture) <= 1 THEN '‚â§ 1 jour'
        WHEN julianday(date_cloture_approx) - julianday(date_ouverture) <= 7 THEN '2-7 jours'
        WHEN julianday(date_cloture_approx) - julianday(date_ouverture) <= 30 THEN '8-30 jours'
        WHEN julianday(date_cloture_approx) - julianday(date_ouverture) <= 90 THEN '31-90 jours'
        ELSE '> 90 jours'
    END AS tranche_delai,
    COUNT(*) AS nb_tickets,
    ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER (), 1) AS pourcentage
FROM tickets
WHERE import_id = ?1
  AND est_vivant = 0
  AND date_cloture_approx IS NOT NULL
GROUP BY tranche_delai
ORDER BY
    CASE tranche_delai
        WHEN '‚â§ 1 jour'    THEN 1
        WHEN '2-7 jours'   THEN 2
        WHEN '8-30 jours'  THEN 3
        WHEN '31-90 jours' THEN 4
        WHEN '> 90 jours'  THEN 5
    END;
```

### 8.4 Comparatif inter-techniciens (bilan d'activit√©)

```sql
SELECT
    technicien_principal,
    COUNT(*) AS nb_resolus,
    ROUND(AVG(julianday(date_cloture_approx) - julianday(date_ouverture)), 1) AS delai_moyen_jours,
    ROUND(AVG(COALESCE(nombre_suivis, 0)), 1) AS suivis_moyen,
    SUM(CASE WHEN type_ticket = 'Incident' THEN 1 ELSE 0 END) AS incidents,
    SUM(CASE WHEN type_ticket = 'Demande' THEN 1 ELSE 0 END) AS demandes,
    SUM(CASE WHEN nombre_suivis <= 1 THEN 1 ELSE 0 END) AS premier_contact
FROM tickets
WHERE import_id = ?1 AND est_vivant = 0
  AND technicien_principal IS NOT NULL
  AND technicien_principal != ''
GROUP BY technicien_principal
ORDER BY nb_resolus DESC;
```

---

## 9. Structure recommand√©e des modules

```
src-tauri/src/
‚îú‚îÄ‚îÄ stats.rs              // moyenne, mediane, ecart_type, percentile, coefficient_variation
‚îú‚îÄ‚îÄ date_utils.rs         // semaine_iso_label, mois_label, jour_label,
‚îÇ                         //   couleur_anciennete, parse_datetime
‚îú‚îÄ‚îÄ classification.rs     // est_vivant, poids_priorite, couleur_charge,
‚îÇ                         //   parse_groupe_hierarchy, lifecycle_order
‚îú‚îÄ‚îÄ analyzer/
‚îÇ   ‚îú‚îÄ‚îÄ mod.rs
‚îÇ   ‚îú‚îÄ‚îÄ stock.rs          // build_stock_kpi(), build_charge_par_technicien()
‚îÇ   ‚îú‚îÄ‚îÄ bilan.rs          // build_bilan_temporel(), calculer_stock_cumule()
‚îÇ   ‚îú‚îÄ‚îÄ ventilation.rs    // ventilation_par_statut(), ventilation_par_groupe(),
‚îÇ   ‚îÇ                     //   pivot_technicien_statut()
‚îÇ   ‚îî‚îÄ‚îÄ delais.rs         // mttr(), distribution_delais(), taux_premier_contact()
‚îú‚îÄ‚îÄ commands/
‚îÇ   ‚îú‚îÄ‚îÄ stock.rs          // #[tauri::command] get_stock_kpi, get_charge_techniciens, etc.
‚îÇ   ‚îî‚îÄ‚îÄ bilan.rs          // #[tauri::command] get_bilan_temporel
‚îî‚îÄ‚îÄ models/
    ‚îú‚îÄ‚îÄ stock.rs           // StockKpiResult, ChargeParTechnicien, VentilationStatut, etc.
    ‚îî‚îÄ‚îÄ bilan.rs           // BilanTemporelResult, BilanTemporelRow, BilanTotaux, etc.
```

---

## 10. R√©capitulatif des d√©cisions d'architecture

|D√©cision|Choix|Justification|
|---|---|---|
|Classification vivant/termin√©|N√©gation : `!matches!(statut, "Clos" \| "R√©solu")`|Tout statut inconnu = vivant (principe de pr√©caution)|
|Calculs statistiques|Rust pur (`Vec<f64>` + tri)|Pas de crate externe, ~50¬µs pour 10K valeurs|
|Agr√©gations comptables|SQL (GROUP BY + CASE WHEN)|Scan unique, pas de transfert de donn√©es|
|Date de cl√¥ture|Proxy via `derniere_modification`|Acceptable pour l'analyse de tendance, document√© comme approximation|
|Stock cumul√© historique|Calcul √† rebours depuis stock connu|Plus fiable que le calcul en avant (snapshot incomplet)|
|Semaine ISO|`strftime('%G-S%V')` SQLite 3.46+ ou `chrono::IsoWeek` Rust|`%Y` + `%V` = bug aux fronti√®res d'ann√©e|
|Seuils couleur|4 niveaux RAG (vert/jaune/orange/rouge)|Standard ITSM, param√©trable via table `config`|
|Pond√©ration priorit√©|Exponentielle (Majeure=10, Tr√®s haute=8, Haute=5, Moyenne=3)|Un P1 ‚â† cinq P4 en effort r√©el|
|Tickets multi-assign√©s|`technicien_principal` (1er de la liste)|Un seul responsable par ticket pour le pilotage|
|Coh√©rence des requ√™tes|Transaction en lecture pour le tableau de bord|Donn√©es coh√©rentes entre toutes les KPI cards|
|Priorit√© ¬´ Majeure ¬ª|Accept√©e avec poids maximal|Pr√©sente dans les donn√©es r√©elles CPAM 92|

---

_Ce segment fournit l'int√©gralit√© de la logique de calcul pour les modules Stock et Bilan du GLPI Dashboard. Il s'appuie sur les structures de donn√©es du Segment 2 (SQLite) et consomme les donn√©es pars√©es par le Segment 1 (CSV). Le Segment 4 (cat√©gories hi√©rarchiques) exploitera les m√™mes patterns de ventilation en ajoutant la dimension cat√©gorielle._